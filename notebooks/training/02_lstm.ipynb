{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57d21537-2c3f-441c-a8cf-32645c716cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "244c02cd-70d4-41a6-94ac-5d2dd34714a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_padded = pad_sequences(X_train_sequences, padding='post', truncating='post', maxlen=40)\n",
    "\n",
    "X_val_sequences = tokenizer.texts_to_sequences(X_val)\n",
    "X_val_padded = pad_sequences(X_val_sequences, padding='post', truncating='post', maxlen=40)\n",
    "\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "X_test_padded = pad_sequences(X_test_sequences, padding='post', truncating='post', maxlen=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32834dbd-0526-4a0a-95a5-3e80386bd012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23870"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "962c6437-c240-41b4-a931-1cc101b1b979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a60b60ed-1dca-45f8-922a-dfef7bcbcd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "vocab_size = len(word_index) + 1\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Embedding(vocab_size, embedding_dim),\n",
    "    layers.Bidirectional(layers.LSTM(128, dropout=0.2, return_sequences=True)),\n",
    "    layers.Bidirectional(layers.LSTM(64, dropout=0.15)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dropout(rate=0.1),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "08023f72-6183-427d-b886-8790d17cad4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, None, 128)         3055488   \n",
      "                                                                 \n",
      " bidirectional_10 (Bidirecti  (None, None, 128)        98816     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " bidirectional_11 (Bidirecti  (None, 64)               41216     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,200,001\n",
      "Trainable params: 3,199,873\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e27bbb83-2396-4bbc-9408-bd9e187326e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4d6da0af-9b86-4a3a-86a9-6adb9404a5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "    metrics.BinaryAccuracy(name='accuracy'),\n",
    "    metrics.Precision(name='precision'),\n",
    "    metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4), \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=METRICS\n",
    ")\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    min_delta=1e-6,\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_learning_rate = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.5, \n",
    "    patience=10, \n",
    "    min_lr=1e-6, \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37bdc667-2dd4-4b72-ae46-dbda59f9a10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d6fcd0cb-dd20-4506-bbfa-709b9cee2480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "656/656 [==============================] - 25s 30ms/step - loss: 0.4709 - accuracy: 0.7638 - precision: 0.7554 - recall: 0.7801 - val_loss: 0.4181 - val_accuracy: 0.8042 - val_precision: 0.9356 - val_recall: 0.6533 - lr: 1.0000e-04\n",
      "Epoch 2/30\n",
      "656/656 [==============================] - 21s 31ms/step - loss: 0.2369 - accuracy: 0.9057 - precision: 0.9007 - recall: 0.9119 - val_loss: 0.3576 - val_accuracy: 0.8516 - val_precision: 0.7844 - val_recall: 0.9697 - lr: 1.0000e-04\n",
      "Epoch 3/30\n",
      "656/656 [==============================] - 25s 38ms/step - loss: 0.1425 - accuracy: 0.9479 - precision: 0.9485 - recall: 0.9474 - val_loss: 0.5452 - val_accuracy: 0.8189 - val_precision: 0.7413 - val_recall: 0.9795 - lr: 1.0000e-04\n",
      "Epoch 4/30\n",
      "656/656 [==============================] - 25s 38ms/step - loss: 0.0949 - accuracy: 0.9668 - precision: 0.9666 - recall: 0.9669 - val_loss: 0.3155 - val_accuracy: 0.8963 - val_precision: 0.8932 - val_recall: 0.9003 - lr: 1.0000e-04\n",
      "Epoch 5/30\n",
      "656/656 [==============================] - 25s 38ms/step - loss: 0.0661 - accuracy: 0.9774 - precision: 0.9783 - recall: 0.9765 - val_loss: 0.3644 - val_accuracy: 0.8934 - val_precision: 0.8717 - val_recall: 0.9226 - lr: 1.0000e-04\n",
      "Epoch 6/30\n",
      "656/656 [==============================] - 24s 37ms/step - loss: 0.0462 - accuracy: 0.9845 - precision: 0.9858 - recall: 0.9832 - val_loss: 0.4298 - val_accuracy: 0.8897 - val_precision: 0.8566 - val_recall: 0.9359 - lr: 1.0000e-04\n",
      "Epoch 7/30\n",
      "656/656 [==============================] - 25s 38ms/step - loss: 0.0329 - accuracy: 0.9892 - precision: 0.9900 - recall: 0.9885 - val_loss: 0.6053 - val_accuracy: 0.8263 - val_precision: 0.9587 - val_recall: 0.6818 - lr: 1.0000e-04\n",
      "Epoch 8/30\n",
      "656/656 [==============================] - 24s 37ms/step - loss: 0.0241 - accuracy: 0.9921 - precision: 0.9927 - recall: 0.9916 - val_loss: 0.4816 - val_accuracy: 0.8897 - val_precision: 0.8535 - val_recall: 0.9408 - lr: 1.0000e-04\n",
      "Epoch 9/30\n",
      "656/656 [==============================] - 24s 37ms/step - loss: 0.0241 - accuracy: 0.9923 - precision: 0.9931 - recall: 0.9915 - val_loss: 0.4818 - val_accuracy: 0.8959 - val_precision: 0.8752 - val_recall: 0.9235 - lr: 1.0000e-04\n",
      "Epoch 10/30\n",
      "656/656 [==============================] - 25s 38ms/step - loss: 0.0172 - accuracy: 0.9946 - precision: 0.9941 - recall: 0.9951 - val_loss: 0.5848 - val_accuracy: 0.8810 - val_precision: 0.8402 - val_recall: 0.9408 - lr: 1.0000e-04\n",
      "Epoch 11/30\n",
      "656/656 [==============================] - 25s 38ms/step - loss: 0.0166 - accuracy: 0.9947 - precision: 0.9949 - recall: 0.9946 - val_loss: 0.4674 - val_accuracy: 0.9001 - val_precision: 0.9006 - val_recall: 0.8994 - lr: 1.0000e-04\n",
      "Epoch 12/30\n",
      "656/656 [==============================] - 24s 37ms/step - loss: 0.0133 - accuracy: 0.9958 - precision: 0.9957 - recall: 0.9958 - val_loss: 0.4957 - val_accuracy: 0.9037 - val_precision: 0.9161 - val_recall: 0.8887 - lr: 1.0000e-04\n",
      "Epoch 13/30\n",
      "656/656 [==============================] - 24s 37ms/step - loss: 0.0102 - accuracy: 0.9968 - precision: 0.9970 - recall: 0.9965 - val_loss: 0.6489 - val_accuracy: 0.8945 - val_precision: 0.8605 - val_recall: 0.9417 - lr: 1.0000e-04\n",
      "Epoch 14/30\n",
      "655/656 [============================>.] - ETA: 0s - loss: 0.0115 - accuracy: 0.9966 - precision: 0.9962 - recall: 0.9969Restoring model weights from the end of the best epoch: 4.\n",
      "\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "656/656 [==============================] - 26s 39ms/step - loss: 0.0115 - accuracy: 0.9966 - precision: 0.9962 - recall: 0.9969 - val_loss: 0.5539 - val_accuracy: 0.8983 - val_precision: 0.9117 - val_recall: 0.8821 - lr: 1.0000e-04\n",
      "Epoch 14: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    tf.constant(X_train_padded), \n",
    "    tf.constant(y_train), \n",
    "    validation_data=(tf.constant(X_val_padded), tf.constant(y_val)),\n",
    "    batch_size=32,\n",
    "    epochs=30,\n",
    "    callbacks=[early_stopping, reduce_learning_rate],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb91975-c4e1-44e7-8a7c-28048a0682bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
